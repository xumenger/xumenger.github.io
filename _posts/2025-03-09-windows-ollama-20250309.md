---
layout: post
title: 大模型实战 - 1：本地搭建ollama 环境
categories: 人工智能与大模型
tags: ollama 大模型 nvidia docker windows 千问 
---

在Windows 环境下搭建大模型环境，机器本身的配置如下：

![](../media/image/2025-03-09/01.png)

![](../media/image/2025-03-09/02.png)

## 安装ollama

官网[https://ollama.com/](https://ollama.com/) 下载比较慢，可以通过[https://ollama.zhike.in/](https://ollama.zhike.in/) 快速下载

下载后正常安装，安装完成后可以看到ollama 命令已经生效

![](../media/image/2025-03-09/03.png)

>以上也是ollama 的一些常用的命令，可以尝试去用一下！

## 相关配置

设置ollama 大模型下载的本地地址，我设置在D 盘，防止C 盘空间快速用完

```
> setx OLLAMA_MODELS "D:\LLM\Ollama"
```

![](../media/image/2025-03-09/04.png)

>否则默认会下载到`C:\Users\<用户名>\.ollama\models` 下面

>还需要注意，配置完环境变量后，需要重启电脑，否则还是会下载到默认路径下！

## 本地运行大模型

[https://ollama.com/search](https://ollama.com/search) 可以搜索各种大模型，比如千问、deepseek-r1 等

![](../media/image/2025-03-09/05.png)

本文搭建千问模型，选择1.8b，一共1.1G 大小

![](../media/image/2025-03-09/06.png)

```shell
ollama run qwen:1.8b
```

下载时间大概是10分钟，可以看到按照预期下载到D:\LLM\Ollama 目录下

![](../media/image/2025-03-09/07.png)

然后尝试提一些问题，可以看到大模型的回答

![](../media/image/2025-03-09/08.png)
